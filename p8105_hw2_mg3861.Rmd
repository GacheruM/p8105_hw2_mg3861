---
title: "Homework 2 - Data Wrangling"
author: "Margaret Gacheru"
output: github_document
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(tidyverse)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_bw() + theme(legend.position = "bottom"))

```

#Problem 1

Importing the data and cleaning by:

1. Retaining line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance variables 

2. Converting the entry variable from character to a logical variable

```{r create_station_dataset, message = FALSE}

station_data = read_csv("NYC_Transit_Data.csv")%>%
  janitor::clean_names()%>%
  select(line, station_name, station_latitude, station_longitude, 
         starts_with("route"), entry, vending, entrance_type, ada)%>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))

```

After importing, the dataset contains 32 variables, including station and entrance location (longitude and latitude), route names and numbers, staffing and staffing hours, entrance types, vending, ADA compliance, and so on. Since not all variables are needed for the analysis, a data cleaning occurs where only line, station, name, station latitude/longitude, routes served, entry, vending, entrance type, and ADA compliance variables were kept. Furthermore, the class of the entry variable is changed. As a result, the remaining NY station dataset contains `r nrow(station_data) ` rows and `r ncol(station_data)` columns. Unfortunately, these data are not tidy, specifically due to the route names and numbers. Each route number should not be a column while the route names should have their own column.  

The are `r distinct(station_data, station_name, line) %>% nrow()`distinct statioins, given that stations are identified both by name and by line. 

```{r}

distinct(station_data, station_name, line)%>%
  nrow()

```

There are `r filter(station_data, ada == "TRUE") %>% count()` stations (not distinct) that are ADA compliant. 

```{r}

filter(station_data, ada == "TRUE") %>%
  count()

```

What proportion of station entrances / exits without vending allow entrance?

```{r}

filter(station_data, vending == "NO")%>%
  pull(entry)%>%
  mean()

```


Reformatting data so that route number and route name are distinct variables. 

```{r reformat_station_dataset, messages= FALSE}
station_data = gather(station_data, key = route_number, 
                      value = route_name, route1:route11 )%>%
  separate(route_number, into = c("Remove", "route_number"), sep = 5)%>%
  select(everything(), -Remove)
```

How many distinct stations serve the A train? 

```{r}

filter(station_data, route_name == "A")%>%
  distinct(station_name, line)%>%
  nrow()

```


Of the stations (not distinct) that serve the A train, how many are ADA compliant?

```{r}

filter(station_data, route_name == "A")%>%
  filter(ada == TRUE)%>%
  count()

```


#Problem 2

Importing the Mr. Trash Wheel dataset and cleaning by:

1. Specifying the Mr. Trash Wheel sheet in the excel file and omitting rows that contain notes

2. Omitting rows that do not include dumpster-specific data

3. Rounding the number of sport balls and converting the variable to an integer

```{r creating_trash_wheel_dataset}

trash_wheel_data = readxl::read_excel("HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 1, 
                                      range = cellranger::cell_cols("A:N"))%>%
  janitor::clean_names()%>%
  filter(!is.na(dumpster))%>%
  mutate(sports_balls = as.integer(ceiling(sports_balls)))
  
```

Importing the precipitation data for 2016 and cleaning by:

1. Omitting rows without precipitation data

2. Adding a year variable

```{r creating_precipitation_2016_dataset}

precipitation_2016_data = readxl::read_excel("HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
                                             sheet = 5, range = "A2:B15")%>%
  janitor::clean_names()%>%
  filter(!is.na(month))%>%
  mutate(year = 2016)

```

Importing the precipitation data for 2017 and cleaning by:

1. Omitting rows without precipitation data

2. Adding a year variable

```{r creating_precipitation_2017_dataset}

precipitation_2017_data = readxl::read_excel("HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
                                             sheet = 4, range = "A2:B15")%>%
  janitor::clean_names()%>%
  filter(!is.na(month), !is.na(total))%>%
  mutate(year = 2017)

```

Merging the precipitation data for 2016 and 2017 and converting month variable into a character

```{r creating_combined_precipitation_dataset}

combined_precipitation_data = bind_rows(precipitation_2016_data, precipitation_2017_data)%>%
  mutate(month = month.name[month])

```

Mr. Trash Wheel dataset contains `r nrow(trash_wheel_data) ` observations while the combined 2016 - 2017 precipitation dataset contains `r nrow(combined_precipitation_data) `
observations. The Trash Wheel data contains the weight and volume of the trash as well as the amount of specific trash items (grocery bags, sports balls, cigarette butts, chip bags, plastic bottles, etc). In the combined precipitation dataset, the key variable is the total column which include the amount of precipitation for a particular month in the respective year. In 2017, the mean total precipitation in a particular month was `r round(mean(precipitation_2017_data$total), 3)` and the median total precipitaton in a particular month was `r median(precipitation_2017_data$total) `. In 2016, the mean total precipitation in a particular month was `r round(mean(precipitation_2016_data$total), 3)` and the median total precipitaton in a particular month was `r median(precipitation_2016_data$total) `. In 2016 and 2017, the highest total precipitation was `r min(combined_precipitation_data$total) ` while the lowest total precipitation was `r max(combined_precipitation_data$total) `

For available data, what was the total precipitation in 2017?

```{r}

sum(precipitation_2017_data$total)

```


What was the median number of sports balls in a dumpster in 2016?

```{r}

filter(trash_wheel_data, year == 2016)%>%
  pull(sports_balls)%>%
  median()

```

#Problem 3

Importing the BRFSS data and cleaning the data by:
 
1. Filtering based on "Overall Health" in the topic variable

2. Retaining class, topic, question, sample size, and all columns between lower confidence limit and GeoLocation

3. Tidying the data (Responses as column names and proportion of the specific responses as the row entries)

4. Creating a new variable that indicates the proportion of "Excellent" or "Very Good" responses

```{r creating_brfss_dataset}

library(p8105.datasets)

brfss = brfss_smart2010%>%
  janitor::clean_names()%>%
  filter(topic == "Overall Health")%>%
  select(everything(), -c(class, topic, question, sample_size, confidence_limit_low:geo_location))%>%
  spread(key = response, value = data_value)%>%
  janitor::clean_names()%>%
  mutate(excellent_or_very_good = excellent + very_good)

```

There are `r distinct(brfss, locationabbr, locationdesc) %>% nrow() ` unique locations are included in the dataset. 

```{r}

distinct(brfss, locationabbr, locationdesc)%>%
  nrow() 

```

Yes, every state is represented. There are `r distinct(brfss, locationabbr) %>% nrow()` states included (DC is considered as a state in the dataset).

```{r}

distinct(brfss, locationabbr)%>%
  nrow()

```

New Jersey is the most observed state.

```{r}

group_by(brfss, locationabbr)%>%
  count()%>%
  arrange(n)%>%
  pull(locationabbr)%>%
  tail(1)

```


In 2002, what is the median of the “Excellent” response value?

```{r}

filter(brfss, year ==  2002)%>%
  pull(excellent)%>%
  median(na.rm = TRUE)

```

Making a histogram of “Excellent” response values in the year 2002

```{r histogram_excellent, warning = FALSE, messages = FALSE}

filter(brfss, year == 2002)%>%
  ggplot(aes(x = excellent)) +
  geom_histogram(fill = "deepskyblue")+
  labs(
    title = "Distribution of Excellent Response Values in 2002",
    x = "Excellent Response Values (%)",
    y = "Count"
  )
ggsave("excellent_response_histogram.pdf", height = 4, width = 6)

```


Make a scatterplot showing the proportion of “Excellent” response values in New York County and Queens County (both in NY State) in each year from 2002 to 2010

```{r scatterplot_excellent_2002to2010}

filter(brfss, year %in% 2002:2010, locationdesc %in% c("NY - New York County", "NY - Queens County"))%>%
  ggplot(aes(x = year, y = excellent/100, color = locationdesc)) +
  geom_point()+
  labs(
    title = "Proportion of Excellent Values in New York and Queens County",
    x = "Year",
    y = "Proportion of Excellent Response Values"
  )+
  scale_color_hue(name = "Location", 
                  h = c(0, 200))
ggsave("excellent_2002_2010_scatterplot.pdf", height = 4, width = 6)

```

