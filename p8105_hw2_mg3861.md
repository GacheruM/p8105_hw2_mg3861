Homework 2 - Data Wrangling
================

Problem 1
=========

Importing the data and cleaning by:

1.  Retaining line, station, name, station latitude / longitude, routes served, entry, vending, entrance type, and ADA compliance variables

2.  Converting the entry variable from character to a logical variable

``` r
station_data = read_csv("NYC_Transit_Data.csv")%>%
  janitor::clean_names()%>%
  select(line, station_name, station_latitude, station_longitude, 
         starts_with("route"), entry, vending, entrance_type, ada)%>%
  mutate(entry = recode(entry, "YES" = TRUE, "NO" = FALSE))
```

After importing, the dataset contains 32 variables, including station and entrance location (longitude and latitude), route names and numbers, staffing and staffing hours, entrance types, vending, ADA compliance, and so on. Since not all variables are needed for the analysis, a data cleaning occurs where only line, station, name, station latitude/longitude, routes served, entry, vending, entrance type, and ADA compliance variables were kept. Furthermore, the class of the entry variable is changed. As a result, the remaining NY station dataset contains 1868 rows and 19 columns. Unfortunately, these data are not tidy, specifically due to the route names and numbers. Each route number should not be a column while the route names should have their own column.

How many distinct stations are there, given that stations are identified both by name and by line?

``` r
distinct(station_data, station_name, line)%>%
  nrow()
```

    ## [1] 465

How many stations are ADA compliant?

``` r
filter(station_data, ada == "TRUE") %>%
  distinct(station_name, line)%>%
  count()
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    84

What proportion of station entrances / exits without vending allow entrance?

``` r
filter(station_data, vending == "NO")%>%
  pull(entry)%>%
  mean()
```

    ## [1] 0.3770492

Reformatting data so that route number and route name are distinct variables.

``` r
station_data = gather(station_data, key = route_number, 
                      value = route_name, route1:route11 )%>%
  separate(route_number, into = c("Remove", "route_number"), sep = 5)%>%
  select(everything(), -Remove)
```

How many distinct stations serve the A train?

``` r
filter(station_data, route_name == "A")%>%
  distinct(station_name, line)%>%
  nrow()
```

    ## [1] 60

Of the stations that serve the A train, how many are ADA compliant?

``` r
filter(station_data, route_name == "A")%>%
  filter(ada == TRUE)%>%
  distinct(station_name, line)%>%
  count()
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    17

Problem 2
=========

Importing the Mr. Trash Wheel dataset and cleaning by:

1.  Specifying the Mr. Trash Wheel sheet in the excel file and omitting rows that contain notes

2.  Omitting rows that do not include dumpster-specific data

3.  Rounding the number of sport balls and converting the variable to an integer

``` r
trash_wheel_data = readxl::read_excel("HealthyHarborWaterWheelTotals2018-7-28.xlsx", sheet = 1, 
                                      range = cellranger::cell_cols("A:N"))%>%
  janitor::clean_names()%>%
  filter(!is.na(dumpster))%>%
  mutate(sports_balls = as.integer(ceiling(sports_balls)))
```

Importing the precipitation data for 2016 and cleaning by:

1.  Omitting rows without precipitation data

2.  Adding a year variable

``` r
precipitation_2016_data = readxl::read_excel("HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
                                             sheet = 5, range = "A2:B15")%>%
  janitor::clean_names()%>%
  filter(!is.na(month))%>%
  mutate(year = 2016)
```

Importing the precipitation data for 2017 and cleaning by:

1.  Omitting rows without precipitation data

2.  Adding a year variable

``` r
precipitation_2017_data = readxl::read_excel("HealthyHarborWaterWheelTotals2018-7-28.xlsx", 
                                             sheet = 4, range = "A2:B15")%>%
  janitor::clean_names()%>%
  filter(!is.na(month), !is.na(total))%>%
  mutate(year = 2017)
```

Merging the precipitation data for 2016 and 2017 and converting month variable into a character

``` r
combined_precipitation_data = bind_rows(precipitation_2016_data, precipitation_2017_data)%>%
  mutate(month = month.name[month])
```

Mr. Trash Wheel dataset contains 285 observations while the combined 2016 - 2017 precipitation dataset contains 24 observations. The Trash Wheel data contains the weight and volume of the trash as well as the amount of specific trash items (grocery bags, sports balls, cigarette butts, chip bags, plastic bottles, etc). In the combined precipitation dataset, the key variable is the total column which include the amount of precipitation for a particular month in the respective year. In 2017, the mean total precipitation in a particular month was 2.744 and the median total precipitaton in a particular month was 2.145. In 2016, the mean total precipitation in a particular month was 3.329 and the median total precipitaton in a particular month was 3.215. In 2016 and 2017, the highest total precipitation was 0 while the lowest total precipitation was 7.09

For available data, what was the total precipitation in 2017?

``` r
sum(precipitation_2017_data$total)
```

    ## [1] 32.93

What was the median number of sports balls in a dumpster in 2016?

``` r
filter(trash_wheel_data, year == 2016)%>%
  pull(sports_balls)%>%
  median()
```

    ## [1] 26

Problem 3
=========

Importing the BRFSS data and cleaning the data by:

1.  Filtering based on "Overall Health" in the topic variable

2.  Retaining class, topic, question, sample size, and all columns between lower confidence limit and GeoLocation

3.  Tidying the data (Responses as column names and proportion of the specific responses as the row entries)

4.  Creating a new variable that indicates the proportion of "Excellent" or "Very Good" responses

``` r
library(p8105.datasets)

brfss = brfss_smart2010%>%
  janitor::clean_names()%>%
  filter(topic == "Overall Health")%>%
  select(everything(), -c(class, topic, question, sample_size, confidence_limit_low:geo_location))%>%
  spread(key = response, value = data_value)%>%
  janitor::clean_names()%>%
  mutate(excellent_or_very_good = excellent + very_good)
```
